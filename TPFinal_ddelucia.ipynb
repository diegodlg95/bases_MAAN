{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_MAAN_ddelucia.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "j0l7pXc2DtO2",
        "W0HOywhatG2p",
        "6PqQYZlarOsl",
        "SxieYx2rsmOw",
        "WEHtfaXyrfQP",
        "1LQNMfjervDF",
        "oc-ofUpOr3WM",
        "Gij33rjNr9MY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_8rLZglx0wd"
      },
      "source": [
        "FACULTAD DE CIENCIAS ECONOMICAS - UNIVERSIDAD DE BUENOS AIRES\n",
        "\n",
        "> **MAESTRIA EN METODOS CUANTITATIVOS PARA LA GESTION Y ANALISIS DE DATOS EN ORGANIZACIONES** \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "TRABAJO FINAL\n",
        "\n",
        "> **ASIGNATURA**: METODOLOGIAS AVANZADAS DE APRENDIZAJE AUTOMATICO\n",
        "\n",
        "> **ALUMNO:** DIEGO DE LUCIA G.\n",
        "\n",
        "> 1er Cuatrimestre 2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0l7pXc2DtO2"
      },
      "source": [
        "# Presentacion e informe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3CEA7uxnct5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import random as rnd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyxYI3Ohcjix",
        "outputId": "8424ed57-391d-44e0-8884-9ffdbfaa4e33"
      },
      "source": [
        "! wget https://github.com/diegodlg95/bases_MAAN/raw/main/marketing_data.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-25 12:25:12--  https://github.com/diegodlg95/bases_MAAN/raw/main/marketing_data.csv\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/diegodlg95/bases_MAAN/main/marketing_data.csv [following]\n",
            "--2021-07-25 12:25:12--  https://raw.githubusercontent.com/diegodlg95/bases_MAAN/main/marketing_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 227054 (222K) [text/plain]\n",
            "Saving to: ‘marketing_data.csv’\n",
            "\n",
            "marketing_data.csv  100%[===================>] 221.73K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-07-25 12:25:13 (12.8 MB/s) - ‘marketing_data.csv’ saved [227054/227054]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVUm3k9E7DWF"
      },
      "source": [
        "****Sobre el dataset:****\n",
        "\n",
        "\n",
        "El dataset consiste en 2.240 registros y 28 variables de clientes sobre una compania anonima, registrados a lo largo de 1 anio donde se presenta informacion sobre:\n",
        "\n",
        "*  Perfil del consumidor\n",
        "*  Preferencias de productos\n",
        "*  Evolucion de campanias previas\n",
        "*  Informacion de canales de venta\n",
        "\n",
        "El conjunto de datos fue obtenido de Kaggle, pero dado que su fin inicial no era para predecir sino mas bien para hacer un analisis exploratorio de los datos, se opto por definir la variable \"Response\" como target a predecir. Dicha variable (binaria), expresa si el cliente acepto o no la ultima campania de Marketing lanzada por la empresa. Como podria esperarse, la distribucion tiene un desbalanceo considerable, cuyo baseline \"natural\" se ubica en 0.8506; es decir que 8,5 de cada 10 personas no acepto la campania.\n",
        "\n",
        "**Descripcion de variables:**\n",
        "\n",
        "*  'Year_Birth': fecha de nacimiento\n",
        "*  'Education': nivel de educacion del cliente\n",
        "*  'Marital_Status': estado civil\n",
        "*  'Income': ingreso anual de unidad familiar\n",
        "*  'Kidhome': cantidad de ninios en la casa\n",
        "*  'Teenhome': cantidad de adolescentes en la casa\n",
        "*  'Dt_Customer': fecha de primer compra del cliente\n",
        "*  'Recency': dias desde la ultima compra\n",
        "*  'MntWines': monto en compras de vino en ultimos 2 anios  \n",
        "*  'MntFruits': monto en compras de frutas en ultimos 2 anios\n",
        "*  'MntMeatProducts': monto en compras de carne en ultimos 2 anios\n",
        "*  'MntFishProducts': monto en compras en pescados en ultimos 2 anios\n",
        "*  'MntSweetProducts': monto en compras de productos dulces en ultimos 2 anios \n",
        "*  'MntGoldProds': monto de compras hechas a traves de la web\n",
        "*  'NumDealsPurchases': cantidad de compras hechas en promocion\n",
        "*  'NumWebPurchases': cantidad de compras hechas a traves de la web\n",
        "*  'NumCatalogPurchases': cantidad de compras hechas a traves de catalogo\n",
        "*  'NumStorePurchases': cantidad de compras hechas a traves de local fisico\n",
        "*  'NumWebVisitsMonth': cantidad de compras hechas a traves de la web.\n",
        "*  'AcceptedCmp3': 1 = si el cliente acepto la oferta en la 3er campania.\n",
        "*  'AcceptedCmp4': 1 = si el cliente acepto la oferta en la 4ta campania.\n",
        "*  'AcceptedCmp5': 1 = si el cliente acepto la oferta en la 5er campania.\n",
        "*  'AcceptedCmp1': 1 = si el cliente acepto la oferta en la 1er campania. \n",
        "*  'AcceptedCmp2': 1 = si el cliente acepto la oferta en la 2da campania.\n",
        "*  'Complain': 1 = si el cliente se quejo en los ultimos 2 anios\n",
        "*  'Country': pais\n",
        "\n",
        "***TARGET:***\n",
        "\n",
        "*  'Response': 1 = si el cliente acepto la oferta en la ultima campania."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hodTaKFmvNvJ"
      },
      "source": [
        "**INFORME:**\n",
        "\n",
        "Consecuentemente con la consigna planteada, en el trabajo desarrollado a continuacion se comenzo en primer lugar realizando un breve Analisis Exploratorio de los datos a traves del cual se generaron nuevas variables y descartaron otras ([EDA](https://colab.research.google.com/drive/1T72EsxlwwhUa7i-eX2ZWMzTyk4JqweuP#scrollTo=FGT4fYBoqxMb&line=2&uniqifier=1)). Por comentar algunas de las modificaciones realizadas, se combinaron ciertas variables mediante operaciones aritmeticas y se combinaron otras, relativas a la cantidad de distintos productos adquiridos por el cliente, mediante Componentes Principales ([Feature Eng](https://colab.research.google.com/drive/1T72EsxlwwhUa7i-eX2ZWMzTyk4JqweuP#scrollTo=sB3qumkKT1dw&line=1&uniqifier=1)). \n",
        "\n",
        "\n",
        "Es de mencionar que del total de variables solo 1 de ellas presento valores perdidos (24; Income), pero para evitar acotar aun mas la ya de por si reducida cantidad de registros, los mismos fueron imputados. Por otro lado, si bien se detectaron ciertas variables con valores considerables como anomalos/outliers, solo se acciono sobre uno de ellos mediante la remocion de los mismos (3 clientes nacidos antes de 1910).\n",
        "\n",
        "Luego de esto, y habiendo previamente normalizado los valores, se fracciono el dataset en un conjunto de prueba y otro de entrenamiento, para proceder en primera instancia a recodificar las variables categoricas a traves de la tecnica one-hot-encoding. Con estos datos, y tomando como metrica objetivo el accuracy (tambien podria haberse optado por considerar un metrica como F1-score o Precision dada la naturaleza del problema), se [optimizaron 3 diferentes modelos](https://colab.research.google.com/drive/1T72EsxlwwhUa7i-eX2ZWMzTyk4JqweuP#scrollTo=Vl6K0ejNStmS&line=1&uniqifier=1): \n",
        "\n",
        "*   Regresion Logistica\n",
        "*   Random Forest\n",
        "*   Sequential NN\n",
        "\n",
        "La optimizacion para los primeros dos, fue mediante una prueba combinatoria exhaustiva (con GridSearch y Cross Validation) y la de la Red Neuronal se realizo mediante la utilizacion de [Algoritmo Genetico](https://colab.research.google.com/drive/1T72EsxlwwhUa7i-eX2ZWMzTyk4JqweuP#scrollTo=6OJ9-qJNPhuc&line=1&uniqifier=1) (probando con hasta 3 capas densas).\n",
        "\n",
        "Comparando los 3 modelos, se encontro que los mejores resultados fueron alcanzados por la Red Neuronal multicapa, seguido de cerca por la Regresion Logistica y un poco por detras Random Forest. Los resultados y parametros asociados:\n",
        "\n",
        "*   NN: Accuracy: 0.8995; capas: [85, 40, 35] ; epochs: 300 ; batch_size: 128\n",
        "*   RL: Accuracy: 0.8820 ; {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
        "*   RF: Accuracy: 0.8777 ; {'criterion': 'entropy', 'max_depth': 64, 'n_estimators': 50}\n",
        "\n",
        "En una siguiente instancia, y motivado por los efectos negativos de la expansion de la dimensionalidad resultado de la aplicacion de one-hot-encoding, se experimento reemplazando dicha codificacion por una [Red Nueronal de Embeddings](https://colab.research.google.com/drive/1T72EsxlwwhUa7i-eX2ZWMzTyk4JqweuP#scrollTo=1LQNMfjervDF&line=1&uniqifier=1) sobre las mismas variables categoricas. Con esto, se repitio el mismo procedimiento, [optimizando los 3 algoritmos](https://colab.research.google.com/drive/1T72EsxlwwhUa7i-eX2ZWMzTyk4JqweuP#scrollTo=oc-ofUpOr3WM&line=1&uniqifier=1) arriba mencionados (cabe mencionar que la Red Neuronal deja de ser secuencial debido a la implementacion de distintas capas de embeddings, en parelismo).\n",
        "\n",
        "Los resultados alcanzados con Embeddings en lugar de one-hot, son considerablemente satisfactorios para la [Red Neuronal](https://colab.research.google.com/drive/1T72EsxlwwhUa7i-eX2ZWMzTyk4JqweuP#scrollTo=Gij33rjNr9MY&line=1&uniqifier=1), mejorando la performance respecto a todos los demas resultados obtenidos. Mientras que por el lado de los algoritmos mas tradicionales (Regresion Logistica y Random Forest), la performance empeoro significativamente, llegando a ubicarse casi a la par del baseline \"natural\". A continuacion los puntajes y parametros asociados al modelo:\n",
        "\n",
        "*   NN: Accuracy: 0.9140; capas: [125, 35, 85]; epochs: 300 ; batch_size: 128\n",
        "*   RL: Accuracy: 0.8514; {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
        "*   RF: Accuracy: 0.8440; {'criterion': 'gini', 'max_depth': 32, 'n_estimators': 100}\n",
        "\n",
        "CONCLUSIONES:\n",
        "\n",
        "Tanto aplicando one-hot, como embeddings para tratar las variables categoricas, el mejor modelo para esta problematica resulto ser la red neuronal. Un punto no menor a mencionar, es utilizando one-hot, la Regresion Logistica se ubico levemente por detras, pero es computacionalmente mucho mas eficiente; ahora bien, si se utiliza una red de embeddings, la diferencia en performance compensa por demas al menor tiempo de procesamiento (esto tiene un componente subjetivo, y conforma la opinion del autor para la casuistica aqui presente).\n",
        "\n",
        "Con mas tiempo, se podria probar:\n",
        "\n",
        "*  Balanceando el dataset (over, under sampling u SMOTE).\n",
        "*  Optimizando en base a metrica F1-score o Precision.\n",
        "*  Optimizar mas parametros de la Redes Neuronales, por ej. funciones de activacion, capas de regularizacion (~dropout), learning rate, algoritmo de optimizacion\n",
        "*  Optimizar los nodos y capas de la red de embeddings (idem anterior).\n",
        "*  Probar otros modelos como KNN o Boosted Classification Trees.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0HOywhatG2p"
      },
      "source": [
        "# EDA y Feauture Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGT4fYBoqxMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f331082-400d-44b5-e121-e6e29577a141"
      },
      "source": [
        "df = pd.read_csv(\"marketing_data.csv\")\n",
        "df.head(50)\n",
        "\n",
        "#df.info()\n",
        "\n",
        "df.columns = df.columns.str.replace(' ', '') # ya que hay espacios en nombres de columnas \n",
        "df = df.set_index('ID')\n",
        "# Income esta de tipo Object debido al signo $ \n",
        "df['Income'] = df['Income'].str.replace('$', '')\n",
        "df['Income'] = df['Income'].str.replace(',', '').astype('float')\n",
        "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])\n",
        "df['Dayofweek'] = df['Dt_Customer'].dt.dayofweek\n",
        "df.isna().sum() # 24 NAs en Income -> ~1% del total. Se imputan para no perder observaciones\n",
        "\n",
        "df.info()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2240 entries, 1826 to 4070\n",
            "Data columns (total 28 columns):\n",
            " #   Column               Non-Null Count  Dtype         \n",
            "---  ------               --------------  -----         \n",
            " 0   Year_Birth           2240 non-null   int64         \n",
            " 1   Education            2240 non-null   object        \n",
            " 2   Marital_Status       2240 non-null   object        \n",
            " 3   Income               2216 non-null   float64       \n",
            " 4   Kidhome              2240 non-null   int64         \n",
            " 5   Teenhome             2240 non-null   int64         \n",
            " 6   Dt_Customer          2240 non-null   datetime64[ns]\n",
            " 7   Recency              2240 non-null   int64         \n",
            " 8   MntWines             2240 non-null   int64         \n",
            " 9   MntFruits            2240 non-null   int64         \n",
            " 10  MntMeatProducts      2240 non-null   int64         \n",
            " 11  MntFishProducts      2240 non-null   int64         \n",
            " 12  MntSweetProducts     2240 non-null   int64         \n",
            " 13  MntGoldProds         2240 non-null   int64         \n",
            " 14  NumDealsPurchases    2240 non-null   int64         \n",
            " 15  NumWebPurchases      2240 non-null   int64         \n",
            " 16  NumCatalogPurchases  2240 non-null   int64         \n",
            " 17  NumStorePurchases    2240 non-null   int64         \n",
            " 18  NumWebVisitsMonth    2240 non-null   int64         \n",
            " 19  AcceptedCmp3         2240 non-null   int64         \n",
            " 20  AcceptedCmp4         2240 non-null   int64         \n",
            " 21  AcceptedCmp5         2240 non-null   int64         \n",
            " 22  AcceptedCmp1         2240 non-null   int64         \n",
            " 23  AcceptedCmp2         2240 non-null   int64         \n",
            " 24  Response             2240 non-null   int64         \n",
            " 25  Complain             2240 non-null   int64         \n",
            " 26  Country              2240 non-null   object        \n",
            " 27  Dayofweek            2240 non-null   int64         \n",
            "dtypes: datetime64[ns](1), float64(1), int64(23), object(3)\n",
            "memory usage: 507.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "vbmu5uuMAhQj",
        "outputId": "a64ddb8d-59ba-4cb9-9378-ad9eb013f48a"
      },
      "source": [
        "# Income Na's imputation \n",
        "\n",
        "fig, ax =plt.subplots(1,2, figsize = (16,5))\n",
        "\n",
        "sns.boxplot(df.Income, ax=ax[0]).set_title('Income BoxPlot') \n",
        "sns.distplot(df.Income, ax=ax[1]).set_title('Income Distribution')\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# df[df.Income > 100000]\n",
        "\n",
        "# Se puede ver lo concentrada que esta la distribucion, mas del 99% de los datos estan entre 0 y 100k. Asimismo, se identifica outlier (Income = 666666.0) el cual se descarta por ser radicalmente mayor(+ 3,5x 2do valor maximo)\n",
        "# En lo que respecta a la imputacion de los Nas, se opta por imputar con la mediana debido a su propiedad de robustez ante los valores extremos pertenecientes al menos de 1% restante.\n",
        "\n",
        "df['Income'].fillna(df['Income'].median(),inplace=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tLVwVGkMA0A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "ed9b9a90-b74d-489f-e42b-604f5f44d92e"
      },
      "source": [
        "# EDA: VARIABLES NUMERICAS\n",
        "\n",
        "# df.drop('ID',axis=1).plot(subplots=True, layout=(6,5), kind='box', figsize=(12,14),notch=True, patch_artist=True)\n",
        "# plt.subplots_adjust(wspace=0.5)\n",
        "# variables binarias sin valores anomalos (todo 0 y 1)\n",
        "\n",
        "df.drop(columns=[ 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain']).plot(subplots=True, layout=(5,5), kind='box', figsize=(12,14),notch=True, patch_artist=True)\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "\n",
        "# Year_birth e Income tienen valores anomalos llamativos, se descartan aquellos registros con Year_birth menores a 1910 (suponiendo el dataset tenga cierta antiguedad, maximo de edad 100 anios -> x > 1910)\n",
        "\n",
        "df = df[df.Year_Birth > 1910]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x1008 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB3qumkKT1dw",
        "outputId": "1485ec1f-6047-42a6-fb40-4d125ee948db"
      },
      "source": [
        "# Total Campanias aceptadas\n",
        "campaigns_cols = ['AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2'] \n",
        "df['TotalCampaignsAcc'] = df[campaigns_cols].sum(axis=1)\n",
        "\n",
        "# Total menores en unidad familiar\n",
        "df['Menores'] = df['Kidhome'] + df['Teenhome']\n",
        "\n",
        "dropped = [ 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'Kidhome','Teenhome','Dt_Customer'] # solo se dejan las ultimas 2 campanias\n",
        "\n",
        "df = df.drop(dropped, axis=1) \n",
        "\n",
        "# Recodificacion de variables categoricas\n",
        "categoricas = ['Education','Marital_Status','Country', 'Dayofweek']\n",
        "continuas = df.drop(columns =(categoricas+['Response']),axis=1).columns\n",
        "a_predecir = \"Response\"\n",
        "\n",
        "for i in categoricas:\n",
        "\n",
        "  df[i] = df[i].astype('category')\n",
        "  df[i] = df[i].cat.codes\n",
        "\n",
        "df.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2237 entries, 1826 to 4070\n",
            "Data columns (total 24 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Year_Birth           2237 non-null   int64  \n",
            " 1   Education            2237 non-null   int8   \n",
            " 2   Marital_Status       2237 non-null   int8   \n",
            " 3   Income               2237 non-null   float64\n",
            " 4   Recency              2237 non-null   int64  \n",
            " 5   MntWines             2237 non-null   int64  \n",
            " 6   MntFruits            2237 non-null   int64  \n",
            " 7   MntMeatProducts      2237 non-null   int64  \n",
            " 8   MntFishProducts      2237 non-null   int64  \n",
            " 9   MntSweetProducts     2237 non-null   int64  \n",
            " 10  MntGoldProds         2237 non-null   int64  \n",
            " 11  NumDealsPurchases    2237 non-null   int64  \n",
            " 12  NumWebPurchases      2237 non-null   int64  \n",
            " 13  NumCatalogPurchases  2237 non-null   int64  \n",
            " 14  NumStorePurchases    2237 non-null   int64  \n",
            " 15  NumWebVisitsMonth    2237 non-null   int64  \n",
            " 16  AcceptedCmp4         2237 non-null   int64  \n",
            " 17  AcceptedCmp5         2237 non-null   int64  \n",
            " 18  Response             2237 non-null   int64  \n",
            " 19  Complain             2237 non-null   int64  \n",
            " 20  Country              2237 non-null   int8   \n",
            " 21  Dayofweek            2237 non-null   int8   \n",
            " 22  TotalCampaignsAcc    2237 non-null   int64  \n",
            " 23  Menores              2237 non-null   int64  \n",
            "dtypes: float64(1), int64(19), int8(4)\n",
            "memory usage: 375.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L3B63UYTNpM",
        "outputId": "22f6aad1-0143-4a4d-e05f-07be4367e4a3"
      },
      "source": [
        "# Split en X e y + baseline\n",
        "\n",
        "X =  df.drop(a_predecir, axis=1)\n",
        "y = df[a_predecir]\n",
        "\n",
        "X.info()\n",
        "print(X.shape,y.shape,'Baseline %:',1-sum(y)/len(y))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2237 entries, 1826 to 4070\n",
            "Data columns (total 23 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Year_Birth           2237 non-null   int64  \n",
            " 1   Education            2237 non-null   int8   \n",
            " 2   Marital_Status       2237 non-null   int8   \n",
            " 3   Income               2237 non-null   float64\n",
            " 4   Recency              2237 non-null   int64  \n",
            " 5   MntWines             2237 non-null   int64  \n",
            " 6   MntFruits            2237 non-null   int64  \n",
            " 7   MntMeatProducts      2237 non-null   int64  \n",
            " 8   MntFishProducts      2237 non-null   int64  \n",
            " 9   MntSweetProducts     2237 non-null   int64  \n",
            " 10  MntGoldProds         2237 non-null   int64  \n",
            " 11  NumDealsPurchases    2237 non-null   int64  \n",
            " 12  NumWebPurchases      2237 non-null   int64  \n",
            " 13  NumCatalogPurchases  2237 non-null   int64  \n",
            " 14  NumStorePurchases    2237 non-null   int64  \n",
            " 15  NumWebVisitsMonth    2237 non-null   int64  \n",
            " 16  AcceptedCmp4         2237 non-null   int64  \n",
            " 17  AcceptedCmp5         2237 non-null   int64  \n",
            " 18  Complain             2237 non-null   int64  \n",
            " 19  Country              2237 non-null   int8   \n",
            " 20  Dayofweek            2237 non-null   int8   \n",
            " 21  TotalCampaignsAcc    2237 non-null   int64  \n",
            " 22  Menores              2237 non-null   int64  \n",
            "dtypes: float64(1), int64(18), int8(4)\n",
            "memory usage: 358.3 KB\n",
            "(2237, 23) (2237,) Baseline %: 0.8506928922664283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "YsbQaRbY8pSS",
        "outputId": "db02d338-ec4a-499c-e47b-e079a83c8a4e"
      },
      "source": [
        "# Standarizacion de Columnas numericas\n",
        "\n",
        "scaler = StandardScaler()\n",
        "#num_cols = X.select_dtypes(include=numerics).drop(['Year_Birth','Dayofweek'], axis =1).columns\n",
        "\n",
        "X_scaled = scaler.fit_transform(X[continuas].values)\n",
        "\n",
        "X_scaled = pd.DataFrame(X_scaled,index=X.drop(continuas,axis=1).index, columns=continuas)\n",
        "X_scaled = pd.concat([X_scaled, X.drop(continuas, axis=1)], axis=1)\n",
        "\n",
        "X_scaled.head(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year_Birth</th>\n",
              "      <th>Income</th>\n",
              "      <th>Recency</th>\n",
              "      <th>MntWines</th>\n",
              "      <th>MntFruits</th>\n",
              "      <th>MntMeatProducts</th>\n",
              "      <th>MntFishProducts</th>\n",
              "      <th>MntSweetProducts</th>\n",
              "      <th>MntGoldProds</th>\n",
              "      <th>NumDealsPurchases</th>\n",
              "      <th>NumWebPurchases</th>\n",
              "      <th>NumCatalogPurchases</th>\n",
              "      <th>NumStorePurchases</th>\n",
              "      <th>NumWebVisitsMonth</th>\n",
              "      <th>AcceptedCmp4</th>\n",
              "      <th>AcceptedCmp5</th>\n",
              "      <th>Complain</th>\n",
              "      <th>TotalCampaignsAcc</th>\n",
              "      <th>Menores</th>\n",
              "      <th>Education</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Country</th>\n",
              "      <th>Dayofweek</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1826</th>\n",
              "      <td>0.093881</td>\n",
              "      <td>1.302341</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>-0.341741</td>\n",
              "      <td>1.957573</td>\n",
              "      <td>0.940040</td>\n",
              "      <td>1.345050</td>\n",
              "      <td>3.922303</td>\n",
              "      <td>3.344011</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.031369</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>0.063267</td>\n",
              "      <td>-1.780485</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.675395</td>\n",
              "      <td>0.194251</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>0.475497</td>\n",
              "      <td>-0.535684</td>\n",
              "      <td>-0.456170</td>\n",
              "      <td>-0.558746</td>\n",
              "      <td>-0.655663</td>\n",
              "      <td>-0.133904</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>1.048218</td>\n",
              "      <td>0.115473</td>\n",
              "      <td>0.370940</td>\n",
              "      <td>-0.131574</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>1.035104</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10476</th>\n",
              "      <td>-0.931821</td>\n",
              "      <td>0.600679</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>-0.505189</td>\n",
              "      <td>-0.384577</td>\n",
              "      <td>-0.478332</td>\n",
              "      <td>-0.412300</td>\n",
              "      <td>-0.607218</td>\n",
              "      <td>-0.268409</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>-0.226664</td>\n",
              "      <td>-0.244405</td>\n",
              "      <td>-1.368257</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1386</th>\n",
              "      <td>-0.162544</td>\n",
              "      <td>-0.788948</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>-0.873689</td>\n",
              "      <td>-0.661606</td>\n",
              "      <td>-0.735412</td>\n",
              "      <td>-0.686886</td>\n",
              "      <td>-0.655663</td>\n",
              "      <td>-0.844859</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-1.167421</td>\n",
              "      <td>0.692882</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>1.395420</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>1.717910</td>\n",
              "      <td>-1.228286</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>-0.885576</td>\n",
              "      <td>-0.258655</td>\n",
              "      <td>-0.633467</td>\n",
              "      <td>-0.485523</td>\n",
              "      <td>-0.655663</td>\n",
              "      <td>-0.191549</td>\n",
              "      <td>-0.169096</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>-0.568802</td>\n",
              "      <td>-1.167421</td>\n",
              "      <td>0.692882</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>1.035104</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7348</th>\n",
              "      <td>-0.931821</td>\n",
              "      <td>0.777372</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>0.095110</td>\n",
              "      <td>2.612368</td>\n",
              "      <td>1.081877</td>\n",
              "      <td>3.706489</td>\n",
              "      <td>0.119443</td>\n",
              "      <td>-0.018614</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.031369</td>\n",
              "      <td>1.484023</td>\n",
              "      <td>-0.244405</td>\n",
              "      <td>-1.368257</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4073</th>\n",
              "      <td>-1.273722</td>\n",
              "      <td>0.452781</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>1.381889</td>\n",
              "      <td>1.353147</td>\n",
              "      <td>0.377124</td>\n",
              "      <td>-0.412300</td>\n",
              "      <td>0.167887</td>\n",
              "      <td>0.404116</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>2.127805</td>\n",
              "      <td>2.510435</td>\n",
              "      <td>0.370940</td>\n",
              "      <td>0.280654</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>1.035104</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>-0.162544</td>\n",
              "      <td>-0.291417</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>-0.671608</td>\n",
              "      <td>-0.661606</td>\n",
              "      <td>-0.691088</td>\n",
              "      <td>-0.686886</td>\n",
              "      <td>-0.655663</td>\n",
              "      <td>-0.710354</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.751094</td>\n",
              "      <td>-0.568802</td>\n",
              "      <td>-0.859749</td>\n",
              "      <td>-0.131574</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4047</th>\n",
              "      <td>-1.273722</td>\n",
              "      <td>0.523076</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>0.237755</td>\n",
              "      <td>-0.661606</td>\n",
              "      <td>-0.287738</td>\n",
              "      <td>-0.302466</td>\n",
              "      <td>0.119443</td>\n",
              "      <td>-0.748784</td>\n",
              "      <td>0.348371</td>\n",
              "      <td>0.688356</td>\n",
              "      <td>-0.226664</td>\n",
              "      <td>0.986284</td>\n",
              "      <td>-0.543802</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9477</th>\n",
              "      <td>-1.273722</td>\n",
              "      <td>0.523076</td>\n",
              "      <td>-1.69621</td>\n",
              "      <td>0.237755</td>\n",
              "      <td>-0.661606</td>\n",
              "      <td>-0.287738</td>\n",
              "      <td>-0.302466</td>\n",
              "      <td>0.119443</td>\n",
              "      <td>-0.748784</td>\n",
              "      <td>0.348371</td>\n",
              "      <td>0.688356</td>\n",
              "      <td>-0.226664</td>\n",
              "      <td>0.986284</td>\n",
              "      <td>-0.543802</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Year_Birth    Income  Recency  MntWines  MntFruits  MntMeatProducts  \\\n",
              "ID                                                                           \n",
              "1826     0.093881  1.302341 -1.69621 -0.341741   1.957573         0.940040   \n",
              "1       -0.675395  0.194251 -1.69621  0.475497  -0.535684        -0.456170   \n",
              "10476   -0.931821  0.600679 -1.69621 -0.505189  -0.384577        -0.478332   \n",
              "1386    -0.162544 -0.788948 -1.69621 -0.873689  -0.661606        -0.735412   \n",
              "5371     1.717910 -1.228286 -1.69621 -0.885576  -0.258655        -0.633467   \n",
              "7348    -0.931821  0.777372 -1.69621  0.095110   2.612368         1.081877   \n",
              "4073    -1.273722  0.452781 -1.69621  1.381889   1.353147         0.377124   \n",
              "1991    -0.162544 -0.291417 -1.69621 -0.671608  -0.661606        -0.691088   \n",
              "4047    -1.273722  0.523076 -1.69621  0.237755  -0.661606        -0.287738   \n",
              "9477    -1.273722  0.523076 -1.69621  0.237755  -0.661606        -0.287738   \n",
              "\n",
              "       MntFishProducts  MntSweetProducts  MntGoldProds  NumDealsPurchases  \\\n",
              "ID                                                                          \n",
              "1826          1.345050          3.922303      3.344011          -0.686563   \n",
              "1            -0.558746         -0.655663     -0.133904          -0.686563   \n",
              "10476        -0.412300         -0.607218     -0.268409          -0.686563   \n",
              "1386         -0.686886         -0.655663     -0.844859          -0.686563   \n",
              "5371         -0.485523         -0.655663     -0.191549          -0.169096   \n",
              "7348          3.706489          0.119443     -0.018614          -0.686563   \n",
              "4073         -0.412300          0.167887      0.404116          -0.686563   \n",
              "1991         -0.686886         -0.655663     -0.710354          -0.686563   \n",
              "4047         -0.302466          0.119443     -0.748784           0.348371   \n",
              "9477         -0.302466          0.119443     -0.748784           0.348371   \n",
              "\n",
              "       NumWebPurchases  NumCatalogPurchases  NumStorePurchases  \\\n",
              "ID                                                               \n",
              "1826         -0.031369             0.457611           0.063267   \n",
              "1             1.048218             0.115473           0.370940   \n",
              "10476        -0.391232            -0.226664          -0.244405   \n",
              "1386         -1.110957            -0.910939          -1.167421   \n",
              "5371         -0.391232            -0.568802          -1.167421   \n",
              "7348         -0.031369             1.484023          -0.244405   \n",
              "4073          2.127805             2.510435           0.370940   \n",
              "1991         -0.751094            -0.568802          -0.859749   \n",
              "4047          0.688356            -0.226664           0.986284   \n",
              "9477          0.688356            -0.226664           0.986284   \n",
              "\n",
              "       NumWebVisitsMonth  AcceptedCmp4  AcceptedCmp5  Complain  \\\n",
              "ID                                                               \n",
              "1826           -1.780485     -0.284036     -0.279414  -0.09498   \n",
              "1              -0.131574     -0.284036     -0.279414  -0.09498   \n",
              "10476          -1.368257     -0.284036     -0.279414  -0.09498   \n",
              "1386            0.692882     -0.284036     -0.279414  -0.09498   \n",
              "5371            0.692882     -0.284036     -0.279414  -0.09498   \n",
              "7348           -1.368257     -0.284036     -0.279414  -0.09498   \n",
              "4073            0.280654     -0.284036     -0.279414  -0.09498   \n",
              "1991           -0.131574     -0.284036     -0.279414  -0.09498   \n",
              "4047           -0.543802     -0.284036     -0.279414  -0.09498   \n",
              "9477           -0.543802     -0.284036     -0.279414  -0.09498   \n",
              "\n",
              "       TotalCampaignsAcc   Menores  Education  Marital_Status  Country  \\\n",
              "ID                                                                       \n",
              "1826           -0.438816 -1.264618          2               2        6   \n",
              "1               1.035104 -1.264618          2               4        1   \n",
              "10476          -0.438816  0.065401          2               3        7   \n",
              "1386           -0.438816  1.395420          2               5        0   \n",
              "5371            1.035104  0.065401          2               4        6   \n",
              "7348           -0.438816 -1.264618          4               4        6   \n",
              "4073            1.035104 -1.264618          0               3        2   \n",
              "1991           -0.438816  0.065401          2               5        6   \n",
              "4047           -0.438816  0.065401          4               3        7   \n",
              "9477           -0.438816  0.065401          4               3        3   \n",
              "\n",
              "       Dayofweek  \n",
              "ID                \n",
              "1826           0  \n",
              "1              6  \n",
              "10476          1  \n",
              "1386           6  \n",
              "5371           1  \n",
              "7348           0  \n",
              "4073           2  \n",
              "1991           5  \n",
              "4047           5  \n",
              "9477           5  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m31pkF7qD41A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "1dc1c1e7-803d-453e-8f19-78ed0ce33bd7"
      },
      "source": [
        "# Reduzco dimensionalidad, 6 variables de compras de productos distintos por 2 componentes principales\n",
        "buyed_products = ['MntWines', 'MntFruits','MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "products_pca = pca.fit_transform(X_scaled[buyed_products].values)\n",
        "\n",
        "products_pca = pd.DataFrame(products_pca,index=X_scaled[buyed_products].index, columns=['products_pca1','products_pca2'])\n",
        "\n",
        "X_scaled_full = pd.concat([X_scaled.drop(buyed_products, axis=1), products_pca], axis=1)\n",
        "X_scaled_full"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year_Birth</th>\n",
              "      <th>Income</th>\n",
              "      <th>Recency</th>\n",
              "      <th>NumDealsPurchases</th>\n",
              "      <th>NumWebPurchases</th>\n",
              "      <th>NumCatalogPurchases</th>\n",
              "      <th>NumStorePurchases</th>\n",
              "      <th>NumWebVisitsMonth</th>\n",
              "      <th>AcceptedCmp4</th>\n",
              "      <th>AcceptedCmp5</th>\n",
              "      <th>Complain</th>\n",
              "      <th>TotalCampaignsAcc</th>\n",
              "      <th>Menores</th>\n",
              "      <th>Education</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Country</th>\n",
              "      <th>Dayofweek</th>\n",
              "      <th>products_pca1</th>\n",
              "      <th>products_pca2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1826</th>\n",
              "      <td>0.093881</td>\n",
              "      <td>1.302341</td>\n",
              "      <td>-1.696210</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.031369</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>0.063267</td>\n",
              "      <td>-1.780485</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4.504636</td>\n",
              "      <td>-0.893689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.675395</td>\n",
              "      <td>0.194251</td>\n",
              "      <td>-1.696210</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>1.048218</td>\n",
              "      <td>0.115473</td>\n",
              "      <td>0.370940</td>\n",
              "      <td>-0.131574</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>1.035104</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.818988</td>\n",
              "      <td>0.786705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10476</th>\n",
              "      <td>-0.931821</td>\n",
              "      <td>0.600679</td>\n",
              "      <td>-1.696210</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>-0.226664</td>\n",
              "      <td>-0.244405</td>\n",
              "      <td>-1.368257</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.090450</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1386</th>\n",
              "      <td>-0.162544</td>\n",
              "      <td>-0.788948</td>\n",
              "      <td>-1.696210</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-1.167421</td>\n",
              "      <td>0.692882</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>1.395420</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>-1.796183</td>\n",
              "      <td>-0.352122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>1.717910</td>\n",
              "      <td>-1.228286</td>\n",
              "      <td>-1.696210</td>\n",
              "      <td>-0.169096</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>-0.568802</td>\n",
              "      <td>-1.167421</td>\n",
              "      <td>0.692882</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>1.035104</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.272350</td>\n",
              "      <td>-0.200247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10142</th>\n",
              "      <td>0.606732</td>\n",
              "      <td>0.569086</td>\n",
              "      <td>1.723526</td>\n",
              "      <td>-0.169096</td>\n",
              "      <td>0.328493</td>\n",
              "      <td>-0.226664</td>\n",
              "      <td>1.601628</td>\n",
              "      <td>-0.543802</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0.419344</td>\n",
              "      <td>0.299718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5263</th>\n",
              "      <td>0.692208</td>\n",
              "      <td>-0.845582</td>\n",
              "      <td>1.723526</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-0.859749</td>\n",
              "      <td>1.105110</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.460034</td>\n",
              "      <td>-0.368477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.606732</td>\n",
              "      <td>-0.236340</td>\n",
              "      <td>1.723526</td>\n",
              "      <td>-0.169096</td>\n",
              "      <td>0.688356</td>\n",
              "      <td>-0.568802</td>\n",
              "      <td>-0.244405</td>\n",
              "      <td>1.105110</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.149165</td>\n",
              "      <td>-0.013846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>0.777683</td>\n",
              "      <td>0.542846</td>\n",
              "      <td>1.723526</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>0.328493</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>1.293956</td>\n",
              "      <td>-0.956029</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.547502</td>\n",
              "      <td>-1.698406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4070</th>\n",
              "      <td>0.008406</td>\n",
              "      <td>1.703177</td>\n",
              "      <td>1.723526</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>1.408080</td>\n",
              "      <td>0.799748</td>\n",
              "      <td>-0.552077</td>\n",
              "      <td>0.692882</td>\n",
              "      <td>3.520683</td>\n",
              "      <td>3.578916</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>2.509023</td>\n",
              "      <td>1.395420</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2.161381</td>\n",
              "      <td>0.340383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2237 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Year_Birth    Income   Recency  NumDealsPurchases  NumWebPurchases  \\\n",
              "ID                                                                          \n",
              "1826     0.093881  1.302341 -1.696210          -0.686563        -0.031369   \n",
              "1       -0.675395  0.194251 -1.696210          -0.686563         1.048218   \n",
              "10476   -0.931821  0.600679 -1.696210          -0.686563        -0.391232   \n",
              "1386    -0.162544 -0.788948 -1.696210          -0.686563        -1.110957   \n",
              "5371     1.717910 -1.228286 -1.696210          -0.169096        -0.391232   \n",
              "...           ...       ...       ...                ...              ...   \n",
              "10142    0.606732  0.569086  1.723526          -0.169096         0.328493   \n",
              "5263     0.692208 -0.845582  1.723526          -0.686563        -1.110957   \n",
              "22       0.606732 -0.236340  1.723526          -0.169096         0.688356   \n",
              "528      0.777683  0.542846  1.723526          -0.686563         0.328493   \n",
              "4070     0.008406  1.703177  1.723526          -0.686563         1.408080   \n",
              "\n",
              "       NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  \\\n",
              "ID                                                                 \n",
              "1826              0.457611           0.063267          -1.780485   \n",
              "1                 0.115473           0.370940          -0.131574   \n",
              "10476            -0.226664          -0.244405          -1.368257   \n",
              "1386             -0.910939          -1.167421           0.692882   \n",
              "5371             -0.568802          -1.167421           0.692882   \n",
              "...                    ...                ...                ...   \n",
              "10142            -0.226664           1.601628          -0.543802   \n",
              "5263             -0.910939          -0.859749           1.105110   \n",
              "22               -0.568802          -0.244405           1.105110   \n",
              "528               0.457611           1.293956          -0.956029   \n",
              "4070              0.799748          -0.552077           0.692882   \n",
              "\n",
              "       AcceptedCmp4  AcceptedCmp5  Complain  TotalCampaignsAcc   Menores  \\\n",
              "ID                                                                         \n",
              "1826      -0.284036     -0.279414  -0.09498          -0.438816 -1.264618   \n",
              "1         -0.284036     -0.279414  -0.09498           1.035104 -1.264618   \n",
              "10476     -0.284036     -0.279414  -0.09498          -0.438816  0.065401   \n",
              "1386      -0.284036     -0.279414  -0.09498          -0.438816  1.395420   \n",
              "5371      -0.284036     -0.279414  -0.09498           1.035104  0.065401   \n",
              "...             ...           ...       ...                ...       ...   \n",
              "10142     -0.284036     -0.279414  -0.09498          -0.438816  0.065401   \n",
              "5263      -0.284036     -0.279414  -0.09498          -0.438816  0.065401   \n",
              "22        -0.284036     -0.279414  -0.09498          -0.438816  0.065401   \n",
              "528       -0.284036     -0.279414  -0.09498          -0.438816 -1.264618   \n",
              "4070       3.520683      3.578916  -0.09498           2.509023  1.395420   \n",
              "\n",
              "       Education  Marital_Status  Country  Dayofweek  products_pca1  \\\n",
              "ID                                                                    \n",
              "1826           2               2        6          0       4.504636   \n",
              "1              2               4        1          6      -0.818988   \n",
              "10476          2               3        7          1      -1.090450   \n",
              "1386           2               5        0          6      -1.796183   \n",
              "5371           2               4        6          1      -1.272350   \n",
              "...          ...             ...      ...        ...            ...   \n",
              "10142          4               2        7          3       0.419344   \n",
              "5263           0               3        6          1      -1.460034   \n",
              "22             2               2        6          0      -1.149165   \n",
              "528            2               3        3          3       3.547502   \n",
              "4070           4               3        1          5       2.161381   \n",
              "\n",
              "       products_pca2  \n",
              "ID                    \n",
              "1826       -0.893689  \n",
              "1           0.786705  \n",
              "10476       0.002200  \n",
              "1386       -0.352122  \n",
              "5371       -0.200247  \n",
              "...              ...  \n",
              "10142       0.299718  \n",
              "5263       -0.368477  \n",
              "22         -0.013846  \n",
              "528        -1.698406  \n",
              "4070        0.340383  \n",
              "\n",
              "[2237 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn-UtCBWVjP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145cacc6-db86-414b-b746-b9018511981a"
      },
      "source": [
        "# Dummies\n",
        "X_scaled_dum = pd.get_dummies(X_scaled_full, columns=categoricas)\n",
        "\n",
        "X_scaled_dum.head(), X_scaled_dum.shape\n",
        "\n",
        "# Split train, test con dummies\n",
        "X_dum_train, X_dum_test, y_dum_train, y_dum_test = train_test_split(X_scaled_dum, y, test_size=0.2, random_state=42, stratify = y)\n",
        "\n",
        "print( 'Shapes:', X_dum_train.shape, X_dum_test.shape, y_dum_train.shape, y_dum_test.shape,'; y = 1 proportion %:',sum(y_dum_test)/len(y_dum_test), sum(y_dum_train)/len(y_dum_train))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (1789, 43) (448, 43) (1789,) (448,) ; y = 1 proportion %: 0.14955357142857142 0.14924538848518726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PqQYZlarOsl"
      },
      "source": [
        "# Regresion logistica y Random Forest con dummies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl6K0ejNStmS",
        "outputId": "ef66bce8-f547-4801-e730-9c8539495eef"
      },
      "source": [
        "# Modelo 1 - 1er anio: REGRESION LOGISTICA con dummies\n",
        "\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2','l1']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "metrics_rlog_dum = []\n",
        "\n",
        "# grid search con CrossValidation\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv = cv,scoring='accuracy',error_score=0) # ,cv = cv \n",
        "grid_result = grid_search.fit(X_dum_train, y_dum_train)\n",
        "\n",
        "# resultados\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  metrics_rlog_dum.append((mean, stdev, param))\n",
        "\n",
        "metrics_rlog_dum = pd.DataFrame(metrics_rlog_dum, columns= ['mean','stdev','params2']).sort_values(by='mean',ascending =False)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) # Best: 0.882059 using {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
        "\n",
        "# confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
        "# sns.heatmap(confusion_matrix, annot=True,cmap='Blues', fmt='g')\n",
        "\n",
        "# print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
        "# plt.show() "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.882059 using {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6bljb3VCiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2963c805-fd2c-4f2a-b537-08faa3c6d69c"
      },
      "source": [
        "# Modelo 2 - 1er anio: RANDOM FOREST con dummies\n",
        "\n",
        "model_2 = RandomForestClassifier(class_weight='balanced')\n",
        "criterion = ['gini','entropy']\n",
        "max_depth = [2,4,8,16,32,64,128]\n",
        "n_estimators = [10,25,50,75,100,150,300]\n",
        "metrics_rf_dum = []\n",
        "\n",
        "# define grid search\n",
        "grid_2 = dict(criterion=criterion,max_depth=max_depth,n_estimators=n_estimators)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "grid_search_2 = GridSearchCV(estimator=model_2, param_grid=grid_2, n_jobs=-1,cv = cv, scoring='accuracy',error_score=0) # ,cv = cv \n",
        "grid_result_2 = grid_search_2.fit(X_dum_train, y_dum_train)\n",
        "\n",
        "# summarize results\n",
        "means_2 = grid_result_2.cv_results_['mean_test_score']\n",
        "stds_2 = grid_result_2.cv_results_['std_test_score']\n",
        "params_2 = grid_result_2.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means_2, stds_2, params_2):\n",
        "    metrics_rf_dum.append((mean,stdev,param))  \n",
        "\n",
        "metrics_rf_dum = pd.DataFrame(metrics_rf_dum, columns= ['mean','stdev','params2']).sort_values(by='mean',ascending =False)\n",
        "print(\"Best: %f using %s\" % (grid_result_2.best_score_, grid_result_2.best_params_)) # Best: 0.877772 using {'criterion': 'entropy', 'max_depth': 64, 'n_estimators': 50}\n",
        "0.882059 using {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.877772 using {'criterion': 'entropy', 'max_depth': 64, 'n_estimators': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxieYx2rsmOw"
      },
      "source": [
        "# Algoritmo genetico para optimizar NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OJ9-qJNPhuc",
        "outputId": "eae8af33-03f1-4e3e-cb59-13a6d9d9fe04"
      },
      "source": [
        "def cromosoma_al_azar():\n",
        "  cromosoma = [rnd.randint(1,20)*5,rnd.randint(0,20)*5,rnd.randint(0,20)*5]\n",
        "  return cromosoma\n",
        "cromosoma_al_azar()\n",
        "\n",
        "def cromosomas_al_azar(n_subset):    \n",
        "    subsets = []\n",
        "    for _ in range(n_subset):\n",
        "        i = cromosoma_al_azar() # probar list set \n",
        "        if i in subsets: # sin repeticion\n",
        "          del(i) \n",
        "        else:\n",
        "          subsets.append(i)    \n",
        "    return subsets\n",
        "\n",
        "print(cromosomas_al_azar(5))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[20, 95, 40], [35, 90, 70], [20, 95, 35], [20, 35, 0], [75, 90, 100]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwOngPBjqmQj"
      },
      "source": [
        "# Cruza o recombina dos cromosomas\n",
        "def cruzar(c1, c2, prob_cruce=0.8):\n",
        "  \n",
        "    if rnd.uniform(0,1)<prob_cruce:\n",
        "      capa1 = rnd.randint(0,2)\n",
        "      capa2 = rnd.randint(0,2)\n",
        "      c3,c4= list(c1),list(c2)\n",
        "      \n",
        "      c3[capa1], c4[capa2] = c4[capa1], c3[capa2]\n",
        "      c3[capa2], c4[capa1] = c4[capa1], c3[capa2]       \n",
        "\n",
        "      return c3,c4\n",
        "    else:\n",
        "      return c1, c2\n",
        "\n",
        "c1 = [70, 20, 55]\n",
        "c2 = [90, 0, 90]\n",
        "a,b = cruzar(c1, c2)\n",
        "c1, c2, a,b\n",
        "# muta un cromosoma\n",
        "def mutar(cromosoma, prob_mut=0.8):\n",
        "    capas = rnd.sample([0,2], 2)\n",
        "    new_cromosoma = list(cromosoma)\n",
        "    if rnd.uniform(0,1)<prob_mut:\n",
        "          for capa in capas:\n",
        "            new_cromosoma[capa] = rnd.randint(5,30)*5\n",
        "          return new_cromosoma\n",
        "    pass\n",
        "    return cromosoma\n",
        "\n",
        "i = [70, 20, 55]\n",
        "b = mutar(i)\n",
        "i,b\n",
        "\n",
        "# Selecciona n_cantidad de cromosomas por sus aptitudes\n",
        "def seleccionar(cromosomas, aptitudes, n_cantidad):\n",
        "    # junta aptitudes y poblacion y los ordena por aptitud descendente\n",
        "    s = sorted(zip(aptitudes, cromosomas), key=lambda x:x[0][1], reverse=True)\n",
        "    return [x for x in s[:n_cantidad]]\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEHtfaXyrfQP"
      },
      "source": [
        "# Deep learning: Sequential NN con dummies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgTL2AGPaMMi",
        "outputId": "12229e2c-d117-4a37-e54d-3f5b37c323be"
      },
      "source": [
        "# Neural network con dummies\n",
        "y_dum_train_nn = tf.keras.utils.to_categorical(y_dum_train, 2) \n",
        "y_dum_test_nn = tf.keras.utils.to_categorical(y_dum_test, 2) \n",
        "\n",
        "# Defino red NN con dummies\n",
        "def seq_model_eval(cromosoma, epochs = 100, batch_size = 128):\n",
        "  # Modelo secuencial (no puede haber ramificaciones)\n",
        "  nn_model_dum = tf.keras.models.Sequential()\n",
        "\n",
        "  # Capa de entrada\n",
        "  nn_model_dum.add(tf.keras.layers.InputLayer(input_shape=[X_dum_train.shape[1]]))\n",
        "  # Capa densa # 1\n",
        "  if cromosoma[0]:\n",
        "    nn_model_dum.add(tf.keras.layers.Dense(units=cromosoma[0], activation='sigmoid'))\n",
        "  pass\n",
        "  # Capa densa # 2\n",
        "  if cromosoma[1]>0: \n",
        "    nn_model_dum.add(tf.keras.layers.Dense(units=cromosoma[1], activation='sigmoid'))\n",
        "  pass\n",
        "  # Capa densa # 3\n",
        "  if cromosoma[2]>0: \n",
        "    nn_model_dum.add(tf.keras.layers.Dense(units=cromosoma[2], activation='sigmoid'))\n",
        "  pass\n",
        "  nn_model_dum.add(tf.keras.layers.Dense(units=2, activation='sigmoid'))\n",
        "\n",
        "  # compilamos el modelo antes de correrlo\n",
        "  nn_model_dum.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "  # ajustamos el modelo, con un tamaño del lote dado, una cantidad de épocas, y el % de validación\n",
        "  history = nn_model_dum.fit(X_dum_train, y_dum_train_nn, batch_size=batch_size, epochs=epochs, verbose=False, validation_split=0.10)\n",
        "\n",
        "  # evaluamos el modelo \n",
        "  loss, accuracy  = nn_model_dum.evaluate(X_dum_test, y_dum_test_nn, verbose=False)\n",
        "  return loss, accuracy\n",
        "\n",
        "cromosoma = cromosoma_al_azar()\n",
        "seq_model_eval(cromosoma)\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2831951975822449, 0.890625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDDY4xcjaHSL"
      },
      "source": [
        "# Todo junto\n",
        "# con 10 cromosomas de poblacion inicial y 5 generaciones\n",
        "GENERACIONES = 5\n",
        "TAM_POBLACION = 10\n",
        "Q_EPOCHS = [100,300,500]\n",
        "BATCH_SIZES = [64,128,256]\n",
        "\n",
        "poblacion = cromosomas_al_azar(TAM_POBLACION)\n",
        "mejores = []\n",
        "for generacion in range(GENERACIONES):\n",
        "\n",
        "  for epochs in Q_EPOCHS:\n",
        "\n",
        "    for batch_sizes in BATCH_SIZES:\n",
        "          \n",
        "        aptitudes = [seq_model_eval(i, batch_size=256, epochs=50) for i in poblacion]\n",
        "        mejores.append(seleccionar(poblacion, aptitudes, 2))\n",
        "        mejores = sorted(mejores, key=lambda x:x[0][1], reverse=True)\n",
        "\n",
        "        nuevo_individuo_1, nuevo_individuo_2 = cruzar(mejores[0][0][1], mejores[0][1][1])\n",
        "        nuevo_individuo_3, nuevo_individuo_4 = cruzar(mejores[0][1][1], mejores[0][0][1])\n",
        "\n",
        "        mutacion_1 = mutar(mejores[0][0][1])\n",
        "\n",
        "        mutacion_2 = mutar(mejores[0][1][1])\n",
        "\n",
        "        poblacion = list(list(zip(*mejores[0]))[1]) + \\\n",
        "            [nuevo_individuo_1, nuevo_individuo_2, nuevo_individuo_3, nuevo_individuo_4] + \\\n",
        "            [mutacion_1, mutacion_2]\n",
        "\n",
        "  print(f'Generacion:{generacion}. El mejor hasta ahora es:', mejores[0][0],', epochs:', epochs, ', batch_size:', batch_sizes)\n",
        "\n",
        "#el mejor hasta ahora es: ((0.28828516602516174, 0.8995535969734192), [85, 40, 35]) , epochs: 300 , batch_size: 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-WHsdudbIsR"
      },
      "source": [
        "# BORRAR\n",
        "history = nn_model_dum.fit(X_dum_train, y_dum_train_nn,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=False,\n",
        "                    batch_size=128,\n",
        "                    epochs=100)\n",
        "\n",
        "loss, accuracy  = nn_model_dum.evaluate(X_dum_test, y_dum_test_nn, verbose=False)  # clasificacion\n",
        "loss, accuracy # clasificacion\n",
        "\n",
        "# Utilizando variables dummies, el algoritmo con mejor performance es la Red Neuronal secuencial, seguido por la Logistic Regression y por ultimo Random Forest\n",
        "print('NN:',accuracy,'; RegLog:' ,grid_result.best_score_,'; Random Forest:', grid_result_2.best_score_) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LQNMfjervDF"
      },
      "source": [
        "# Embeddings sobre categoricas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVh5D-glJYLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a540dc17-b28e-441d-d0ba-6490d64b08bd"
      },
      "source": [
        "# Split train, test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled_full, y, test_size=0.2, random_state=42, stratify = y)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1789, 19), (448, 19), (1789,), (448,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "6_-JnZ-z_ddU",
        "outputId": "ba7db6d6-57a2-4d0d-932d-57a9af9a471e"
      },
      "source": [
        "# Embeddings para recodificar categoricas y volver a correr modelos tradicionales (1er anio)\n",
        "X_train_emb, X_test_emb, y_train_emb, y_test_emb = X_train, X_test, y_train, y_test\n",
        "y_train_emb_nn, y_test_emb_nn = tf.keras.utils.to_categorical(y_train_emb), tf.keras.utils.to_categorical(y_test_emb)\n",
        "\n",
        "for cat in categoricas:\n",
        "  n_cats = X_train[cat].max()+1\n",
        "  n_embedding_size = min(50, n_cats//2-1) # cant de neuronas\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(1, )),\n",
        "      tf.keras.layers.Embedding(n_cats, n_embedding_size),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model.fit(X_train[cat], y_train_emb_nn, batch_size=128, epochs=100, validation_data= (X_test[cat], y_test_emb_nn), verbose= False)\n",
        "\n",
        "  loss, accuracy  = model.evaluate(X_test[cat],  y_test_emb_nn, verbose=False)\n",
        "  loss, accuracy\n",
        "  \n",
        "  weights = model.layers[0].get_weights()[0]\n",
        "  weights = pd.DataFrame(weights, columns=[f'{cat}_weight_{c}' for c in range(n_embedding_size)])\n",
        "  weights[cat] = weights.index\n",
        "  \n",
        "  X_train_emb = X_train_emb.merge(weights).drop(cat, axis=1)\n",
        "  X_test_emb = X_test_emb.merge(weights).drop(cat, axis=1)\n",
        "\n",
        "X_train_emb.head()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year_Birth</th>\n",
              "      <th>Income</th>\n",
              "      <th>Recency</th>\n",
              "      <th>NumDealsPurchases</th>\n",
              "      <th>NumWebPurchases</th>\n",
              "      <th>NumCatalogPurchases</th>\n",
              "      <th>NumStorePurchases</th>\n",
              "      <th>NumWebVisitsMonth</th>\n",
              "      <th>AcceptedCmp4</th>\n",
              "      <th>AcceptedCmp5</th>\n",
              "      <th>Complain</th>\n",
              "      <th>TotalCampaignsAcc</th>\n",
              "      <th>Menores</th>\n",
              "      <th>products_pca1</th>\n",
              "      <th>products_pca2</th>\n",
              "      <th>Education_weight_0</th>\n",
              "      <th>Marital_Status_weight_0</th>\n",
              "      <th>Marital_Status_weight_1</th>\n",
              "      <th>Marital_Status_weight_2</th>\n",
              "      <th>Country_weight_0</th>\n",
              "      <th>Country_weight_1</th>\n",
              "      <th>Country_weight_2</th>\n",
              "      <th>Dayofweek_weight_0</th>\n",
              "      <th>Dayofweek_weight_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.521257</td>\n",
              "      <td>0.243736</td>\n",
              "      <td>1.309013</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>0.688356</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>2.216972</td>\n",
              "      <td>-0.543802</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2.493082</td>\n",
              "      <td>0.150865</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.530147</td>\n",
              "      <td>0.741466</td>\n",
              "      <td>1.136299</td>\n",
              "      <td>-0.169096</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>1.293956</td>\n",
              "      <td>-0.956029</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>2.017424</td>\n",
              "      <td>0.522319</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.093881</td>\n",
              "      <td>-0.812672</td>\n",
              "      <td>-1.247154</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-1.167421</td>\n",
              "      <td>1.105110</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>-1.748574</td>\n",
              "      <td>-0.350404</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.444672</td>\n",
              "      <td>-0.486403</td>\n",
              "      <td>-0.901726</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-0.859749</td>\n",
              "      <td>0.280654</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>-1.666190</td>\n",
              "      <td>-0.393599</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.701098</td>\n",
              "      <td>0.815395</td>\n",
              "      <td>0.376357</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>2.510435</td>\n",
              "      <td>0.370940</td>\n",
              "      <td>-1.368257</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>1.035104</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>3.002983</td>\n",
              "      <td>-0.943676</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year_Birth    Income   Recency  NumDealsPurchases  NumWebPurchases  \\\n",
              "0    0.521257  0.243736  1.309013          -0.686563         0.688356   \n",
              "1   -1.530147  0.741466  1.136299          -0.169096        -0.391232   \n",
              "2    0.093881 -0.812672 -1.247154          -0.686563        -1.110957   \n",
              "3   -1.444672 -0.486403 -0.901726          -0.686563        -1.110957   \n",
              "4   -1.701098  0.815395  0.376357          -0.686563        -0.391232   \n",
              "\n",
              "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  AcceptedCmp4  \\\n",
              "0             0.457611           2.216972          -0.543802     -0.284036   \n",
              "1             0.457611           1.293956          -0.956029     -0.284036   \n",
              "2            -0.910939          -1.167421           1.105110     -0.284036   \n",
              "3            -0.910939          -0.859749           0.280654     -0.284036   \n",
              "4             2.510435           0.370940          -1.368257     -0.284036   \n",
              "\n",
              "   AcceptedCmp5  Complain  TotalCampaignsAcc   Menores  products_pca1  \\\n",
              "0     -0.279414  -0.09498          -0.438816  0.065401       2.493082   \n",
              "1     -0.279414  -0.09498          -0.438816 -1.264618       2.017424   \n",
              "2     -0.279414  -0.09498          -0.438816  0.065401      -1.748574   \n",
              "3     -0.279414  -0.09498          -0.438816  0.065401      -1.666190   \n",
              "4     -0.279414  -0.09498           1.035104 -1.264618       3.002983   \n",
              "\n",
              "   products_pca2  Education_weight_0  Marital_Status_weight_0  \\\n",
              "0       0.150865            0.483878                -0.079432   \n",
              "1       0.522319            0.483878                -0.079432   \n",
              "2      -0.350404            0.483878                -0.079432   \n",
              "3      -0.393599            0.483878                -0.079432   \n",
              "4      -0.943676            0.483878                -0.079432   \n",
              "\n",
              "   Marital_Status_weight_1  Marital_Status_weight_2  Country_weight_0  \\\n",
              "0                 0.088244                 0.082499          0.263446   \n",
              "1                 0.088244                 0.082499          0.263446   \n",
              "2                 0.088244                 0.082499          0.263446   \n",
              "3                 0.088244                 0.082499          0.263446   \n",
              "4                 0.088244                 0.082499          0.263446   \n",
              "\n",
              "   Country_weight_1  Country_weight_2  Dayofweek_weight_0  Dayofweek_weight_1  \n",
              "0          0.272072          0.311502           -0.315154           -0.216675  \n",
              "1          0.272072          0.311502           -0.315154           -0.216675  \n",
              "2          0.272072          0.311502           -0.315154           -0.216675  \n",
              "3          0.272072          0.311502           -0.315154           -0.216675  \n",
              "4          0.272072          0.311502           -0.315154           -0.216675  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-ofUpOr3WM"
      },
      "source": [
        "# Regresion Logistica y Random Forest con Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "V2LwbmycPMDz",
        "outputId": "c1ba7f66-25e3-40c4-9d9c-98bb27132e6d"
      },
      "source": [
        "# Modelo 1 - 1er anio: REGRESION LOGISTICA con EMBEDDINGS\n",
        "\n",
        "model = LogisticRegression() # se probo cambiando los pesos de clases a predecir, w = {0:15, 1:85} pero performa muy mal -> 0.59 acc. Probar optimizando\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2','l1']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "metrics_rlog_emb = []\n",
        "\n",
        "# grid search con CrossValidation\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv = cv,scoring='accuracy',error_score=0) # ,cv = cv \n",
        "grid_result = grid_search.fit(X_train_emb, y_train)\n",
        "\n",
        "# resultados\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  metrics_rlog_emb.append((mean, stdev, param))\n",
        "\n",
        "metrics_rlog_emb = pd.DataFrame(metrics_rlog_emb, columns= ['mean','stdev','params2']).sort_values(by='mean',ascending =False)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) # Best: 0.851499 using {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year_Birth</th>\n",
              "      <th>Income</th>\n",
              "      <th>Recency</th>\n",
              "      <th>NumDealsPurchases</th>\n",
              "      <th>NumWebPurchases</th>\n",
              "      <th>NumCatalogPurchases</th>\n",
              "      <th>NumStorePurchases</th>\n",
              "      <th>NumWebVisitsMonth</th>\n",
              "      <th>AcceptedCmp4</th>\n",
              "      <th>AcceptedCmp5</th>\n",
              "      <th>Complain</th>\n",
              "      <th>TotalCampaignsAcc</th>\n",
              "      <th>Menores</th>\n",
              "      <th>products_pca1</th>\n",
              "      <th>products_pca2</th>\n",
              "      <th>Education_weight_0</th>\n",
              "      <th>Marital_Status_weight_0</th>\n",
              "      <th>Marital_Status_weight_1</th>\n",
              "      <th>Marital_Status_weight_2</th>\n",
              "      <th>Country_weight_0</th>\n",
              "      <th>Country_weight_1</th>\n",
              "      <th>Country_weight_2</th>\n",
              "      <th>Dayofweek_weight_0</th>\n",
              "      <th>Dayofweek_weight_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.521257</td>\n",
              "      <td>0.243736</td>\n",
              "      <td>1.309013</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>0.688356</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>2.216972</td>\n",
              "      <td>-0.543802</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>2.493082</td>\n",
              "      <td>0.150865</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.530147</td>\n",
              "      <td>0.741466</td>\n",
              "      <td>1.136299</td>\n",
              "      <td>-0.169096</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>0.457611</td>\n",
              "      <td>1.293956</td>\n",
              "      <td>-0.956029</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>2.017424</td>\n",
              "      <td>0.522319</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.093881</td>\n",
              "      <td>-0.812672</td>\n",
              "      <td>-1.247154</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-1.167421</td>\n",
              "      <td>1.105110</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>-1.748574</td>\n",
              "      <td>-0.350404</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.444672</td>\n",
              "      <td>-0.486403</td>\n",
              "      <td>-0.901726</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-0.859749</td>\n",
              "      <td>0.280654</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>-1.666190</td>\n",
              "      <td>-0.393599</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.701098</td>\n",
              "      <td>0.815395</td>\n",
              "      <td>0.376357</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-0.391232</td>\n",
              "      <td>2.510435</td>\n",
              "      <td>0.370940</td>\n",
              "      <td>-1.368257</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>1.035104</td>\n",
              "      <td>-1.264618</td>\n",
              "      <td>3.002983</td>\n",
              "      <td>-0.943676</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.079432</td>\n",
              "      <td>0.088244</td>\n",
              "      <td>0.082499</td>\n",
              "      <td>0.263446</td>\n",
              "      <td>0.272072</td>\n",
              "      <td>0.311502</td>\n",
              "      <td>-0.315154</td>\n",
              "      <td>-0.216675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>0.264832</td>\n",
              "      <td>-0.016551</td>\n",
              "      <td>-0.418127</td>\n",
              "      <td>-0.169096</td>\n",
              "      <td>-0.751094</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-0.859749</td>\n",
              "      <td>0.692882</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>1.395420</td>\n",
              "      <td>-1.694258</td>\n",
              "      <td>-0.282163</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.240546</td>\n",
              "      <td>0.139790</td>\n",
              "      <td>0.161987</td>\n",
              "      <td>0.303965</td>\n",
              "      <td>0.304204</td>\n",
              "      <td>0.326719</td>\n",
              "      <td>-0.376329</td>\n",
              "      <td>-0.296665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1785</th>\n",
              "      <td>0.179357</td>\n",
              "      <td>-0.454372</td>\n",
              "      <td>0.479986</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.568802</td>\n",
              "      <td>-1.167421</td>\n",
              "      <td>0.692882</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>1.395420</td>\n",
              "      <td>-1.561580</td>\n",
              "      <td>-0.125105</td>\n",
              "      <td>0.483878</td>\n",
              "      <td>-0.240546</td>\n",
              "      <td>0.139790</td>\n",
              "      <td>0.161987</td>\n",
              "      <td>0.303965</td>\n",
              "      <td>0.304204</td>\n",
              "      <td>0.326719</td>\n",
              "      <td>-0.376329</td>\n",
              "      <td>-0.296665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1786</th>\n",
              "      <td>-0.504445</td>\n",
              "      <td>-0.109891</td>\n",
              "      <td>-0.694469</td>\n",
              "      <td>0.865837</td>\n",
              "      <td>-0.751094</td>\n",
              "      <td>2.852573</td>\n",
              "      <td>-0.244405</td>\n",
              "      <td>-1.368257</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>1.185650</td>\n",
              "      <td>1.518085</td>\n",
              "      <td>0.353215</td>\n",
              "      <td>-0.240546</td>\n",
              "      <td>0.139790</td>\n",
              "      <td>0.161987</td>\n",
              "      <td>0.303965</td>\n",
              "      <td>0.304204</td>\n",
              "      <td>0.326719</td>\n",
              "      <td>-0.376329</td>\n",
              "      <td>-0.296665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1787</th>\n",
              "      <td>0.350307</td>\n",
              "      <td>-0.841309</td>\n",
              "      <td>0.169101</td>\n",
              "      <td>-0.686563</td>\n",
              "      <td>-1.110957</td>\n",
              "      <td>-0.910939</td>\n",
              "      <td>-0.859749</td>\n",
              "      <td>0.280654</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>-1.580884</td>\n",
              "      <td>-0.362984</td>\n",
              "      <td>0.546997</td>\n",
              "      <td>-0.240546</td>\n",
              "      <td>0.139790</td>\n",
              "      <td>0.161987</td>\n",
              "      <td>0.303965</td>\n",
              "      <td>0.304204</td>\n",
              "      <td>0.326719</td>\n",
              "      <td>-0.376329</td>\n",
              "      <td>-0.296665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1788</th>\n",
              "      <td>0.350307</td>\n",
              "      <td>-0.151588</td>\n",
              "      <td>-1.592582</td>\n",
              "      <td>1.383304</td>\n",
              "      <td>1.048218</td>\n",
              "      <td>-0.568802</td>\n",
              "      <td>0.063267</td>\n",
              "      <td>1.105110</td>\n",
              "      <td>-0.284036</td>\n",
              "      <td>-0.279414</td>\n",
              "      <td>-0.09498</td>\n",
              "      <td>-0.438816</td>\n",
              "      <td>0.065401</td>\n",
              "      <td>-0.985828</td>\n",
              "      <td>0.582998</td>\n",
              "      <td>0.249417</td>\n",
              "      <td>0.025696</td>\n",
              "      <td>-0.089697</td>\n",
              "      <td>-0.076776</td>\n",
              "      <td>0.303965</td>\n",
              "      <td>0.304204</td>\n",
              "      <td>0.326719</td>\n",
              "      <td>-0.376329</td>\n",
              "      <td>-0.296665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1789 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Year_Birth    Income   Recency  NumDealsPurchases  NumWebPurchases  \\\n",
              "0       0.521257  0.243736  1.309013          -0.686563         0.688356   \n",
              "1      -1.530147  0.741466  1.136299          -0.169096        -0.391232   \n",
              "2       0.093881 -0.812672 -1.247154          -0.686563        -1.110957   \n",
              "3      -1.444672 -0.486403 -0.901726          -0.686563        -1.110957   \n",
              "4      -1.701098  0.815395  0.376357          -0.686563        -0.391232   \n",
              "...          ...       ...       ...                ...              ...   \n",
              "1784    0.264832 -0.016551 -0.418127          -0.169096        -0.751094   \n",
              "1785    0.179357 -0.454372  0.479986          -0.686563        -1.110957   \n",
              "1786   -0.504445 -0.109891 -0.694469           0.865837        -0.751094   \n",
              "1787    0.350307 -0.841309  0.169101          -0.686563        -1.110957   \n",
              "1788    0.350307 -0.151588 -1.592582           1.383304         1.048218   \n",
              "\n",
              "      NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  AcceptedCmp4  \\\n",
              "0                0.457611           2.216972          -0.543802     -0.284036   \n",
              "1                0.457611           1.293956          -0.956029     -0.284036   \n",
              "2               -0.910939          -1.167421           1.105110     -0.284036   \n",
              "3               -0.910939          -0.859749           0.280654     -0.284036   \n",
              "4                2.510435           0.370940          -1.368257     -0.284036   \n",
              "...                   ...                ...                ...           ...   \n",
              "1784            -0.910939          -0.859749           0.692882     -0.284036   \n",
              "1785            -0.568802          -1.167421           0.692882     -0.284036   \n",
              "1786             2.852573          -0.244405          -1.368257     -0.284036   \n",
              "1787            -0.910939          -0.859749           0.280654     -0.284036   \n",
              "1788            -0.568802           0.063267           1.105110     -0.284036   \n",
              "\n",
              "      AcceptedCmp5  Complain  TotalCampaignsAcc   Menores  products_pca1  \\\n",
              "0        -0.279414  -0.09498          -0.438816  0.065401       2.493082   \n",
              "1        -0.279414  -0.09498          -0.438816 -1.264618       2.017424   \n",
              "2        -0.279414  -0.09498          -0.438816  0.065401      -1.748574   \n",
              "3        -0.279414  -0.09498          -0.438816  0.065401      -1.666190   \n",
              "4        -0.279414  -0.09498           1.035104 -1.264618       3.002983   \n",
              "...            ...       ...                ...       ...            ...   \n",
              "1784     -0.279414  -0.09498          -0.438816  1.395420      -1.694258   \n",
              "1785     -0.279414  -0.09498          -0.438816  1.395420      -1.561580   \n",
              "1786     -0.279414  -0.09498          -0.438816  0.065401       1.185650   \n",
              "1787     -0.279414  -0.09498          -0.438816  0.065401      -1.580884   \n",
              "1788     -0.279414  -0.09498          -0.438816  0.065401      -0.985828   \n",
              "\n",
              "      products_pca2  Education_weight_0  Marital_Status_weight_0  \\\n",
              "0          0.150865            0.483878                -0.079432   \n",
              "1          0.522319            0.483878                -0.079432   \n",
              "2         -0.350404            0.483878                -0.079432   \n",
              "3         -0.393599            0.483878                -0.079432   \n",
              "4         -0.943676            0.483878                -0.079432   \n",
              "...             ...                 ...                      ...   \n",
              "1784      -0.282163            0.483878                -0.240546   \n",
              "1785      -0.125105            0.483878                -0.240546   \n",
              "1786       1.518085            0.353215                -0.240546   \n",
              "1787      -0.362984            0.546997                -0.240546   \n",
              "1788       0.582998            0.249417                 0.025696   \n",
              "\n",
              "      Marital_Status_weight_1  Marital_Status_weight_2  Country_weight_0  \\\n",
              "0                    0.088244                 0.082499          0.263446   \n",
              "1                    0.088244                 0.082499          0.263446   \n",
              "2                    0.088244                 0.082499          0.263446   \n",
              "3                    0.088244                 0.082499          0.263446   \n",
              "4                    0.088244                 0.082499          0.263446   \n",
              "...                       ...                      ...               ...   \n",
              "1784                 0.139790                 0.161987          0.303965   \n",
              "1785                 0.139790                 0.161987          0.303965   \n",
              "1786                 0.139790                 0.161987          0.303965   \n",
              "1787                 0.139790                 0.161987          0.303965   \n",
              "1788                -0.089697                -0.076776          0.303965   \n",
              "\n",
              "      Country_weight_1  Country_weight_2  Dayofweek_weight_0  \\\n",
              "0             0.272072          0.311502           -0.315154   \n",
              "1             0.272072          0.311502           -0.315154   \n",
              "2             0.272072          0.311502           -0.315154   \n",
              "3             0.272072          0.311502           -0.315154   \n",
              "4             0.272072          0.311502           -0.315154   \n",
              "...                ...               ...                 ...   \n",
              "1784          0.304204          0.326719           -0.376329   \n",
              "1785          0.304204          0.326719           -0.376329   \n",
              "1786          0.304204          0.326719           -0.376329   \n",
              "1787          0.304204          0.326719           -0.376329   \n",
              "1788          0.304204          0.326719           -0.376329   \n",
              "\n",
              "      Dayofweek_weight_1  \n",
              "0              -0.216675  \n",
              "1              -0.216675  \n",
              "2              -0.216675  \n",
              "3              -0.216675  \n",
              "4              -0.216675  \n",
              "...                  ...  \n",
              "1784           -0.296665  \n",
              "1785           -0.296665  \n",
              "1786           -0.296665  \n",
              "1787           -0.296665  \n",
              "1788           -0.296665  \n",
              "\n",
              "[1789 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGukrc1zPMGw",
        "outputId": "e2812ea4-4afd-4590-8168-0ac56b101770"
      },
      "source": [
        "# Modelo 2 - 1er anio: RANDOM FOREST con dummies\n",
        "\n",
        "model_2 = RandomForestClassifier(class_weight='balanced')\n",
        "criterion = ['gini','entropy']\n",
        "max_depth = [2,4,8,16,32,64,128]\n",
        "n_estimators = [10,25,50,75,100,150,300]\n",
        "metrics_rf_emb = []\n",
        "\n",
        "# define grid search\n",
        "grid_2 = dict(criterion=criterion,max_depth=max_depth,n_estimators=n_estimators)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "\n",
        "grid_search_2 = GridSearchCV(estimator=model_2, param_grid=grid_2, n_jobs=-1,cv = cv, scoring='accuracy',error_score=0) # ,cv = cv \n",
        "grid_result_2 = grid_search_2.fit(X_train_emb, y_train)\n",
        "\n",
        "# summarize results\n",
        "means_2 = grid_result_2.cv_results_['mean_test_score']\n",
        "stds_2 = grid_result_2.cv_results_['std_test_score']\n",
        "params_2 = grid_result_2.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means_2, stds_2, params_2):\n",
        "    metrics_rf_emb.append((mean,stdev,param))  \n",
        "\n",
        "metrics_rf_emb = pd.DataFrame(metrics_rf_emb, columns= ['mean','stdev','params2']).sort_values(by='mean',ascending =False)\n",
        "print(\"Best: %f using %s\" % (grid_result_2.best_score_, grid_result_2.best_params_)) # Best: 0.844047 using {'criterion': 'gini', 'max_depth': 32, 'n_estimators': 100}"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.844047 using {'criterion': 'gini', 'max_depth': 32, 'n_estimators': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gij33rjNr9MY"
      },
      "source": [
        "# Deep Learning: Mixed NN - Embeddings y Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyH5lHNifdFU",
        "outputId": "71b3ffbe-370a-4754-819c-eaae265e4b35"
      },
      "source": [
        "continuas = X_scaled_full.drop(columns = categoricas,axis=1).columns \n",
        "\n",
        "cromosoma = cromosoma_al_azar()\n",
        "\n",
        "def mixed_nn_model_eval(cromosoma, epochs = 100, batch_size = 128):\n",
        "\n",
        "  embeddings = []\n",
        "  inputs = []\n",
        "\n",
        "  for c in categoricas:\n",
        "      n_cats = X_scaled_full[c].max()+1\n",
        "      n_emb_size = min(50, n_cats//2+1)\n",
        "      inp = tf.keras.layers.Input(shape=[1], name=f'inp_{c.replace(\" \", \"_\")}')\n",
        "      emb = tf.keras.layers.Embedding(n_cats, n_emb_size, name=f'emb_{c.replace(\" \", \"_\")}')(inp)\n",
        "\n",
        "      inputs.append(inp)\n",
        "      embeddings.append(emb)\n",
        "\n",
        "  embs = tf.keras.layers.concatenate(embeddings)\n",
        "  flatten_embs = tf.keras.layers.Flatten()(embs)\n",
        "\n",
        "  inp_continuas = tf.keras.layers.Input(shape=len(continuas), name='inp_continuas')\n",
        "\n",
        "  flatten_embs_conts = tf.keras.layers.concatenate([flatten_embs, inp_continuas])\n",
        "\n",
        "  if cromosoma[0]>1:\n",
        "    dense01 = tf.keras.layers.Dense(cromosoma[0], activation='sigmoid', name='dense01')(flatten_embs_conts)\n",
        "\n",
        "    if cromosoma[1]>0:\n",
        "      dense02 = tf.keras.layers.Dense(cromosoma[1], activation='sigmoid', name='dense02')(dense01)\n",
        "      \n",
        "      if cromosoma[2]>0:\n",
        "        dense03 = tf.keras.layers.Dense(cromosoma[2], activation='sigmoid', name='dense03')(dense02)\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense03)\n",
        "      else:\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense02)\n",
        "\n",
        "    else: \n",
        "      if cromosoma[2]>0:\n",
        "        dense02 = tf.keras.layers.Dense(cromosoma[2], activation='sigmoid', name='dense02')(dense01)\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense02)\n",
        "      else:\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense01)\n",
        "  else:\n",
        "    if cromosoma[1]>0:\n",
        "      dense01 = tf.keras.layers.Dense(cromosoma[1], activation='sigmoid', name='dense02')(flatten_embs_conts)\n",
        "      \n",
        "      if cromosoma[2]>0:\n",
        "        dense02 = tf.keras.layers.Dense(cromosoma[2], activation='sigmoid', name='dense03')(dense01)\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense02)\n",
        "      else:\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense01)\n",
        "\n",
        "    else:\n",
        "      if cromosoma[2]>0:\n",
        "        dense01 = tf.keras.layers.Dense(cromosoma[2], activation='sigmoid', name='dense02')(flatten_embs_conts)\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense01)\n",
        "      else:\n",
        "        dense01 = tf.keras.layers.Dense(rnd.randint(15,30)*5, activation='sigmoid', name='dense02')(flatten_embs_conts)\n",
        "        outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='output')(dense01)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=inputs+[inp_continuas], outputs=outputs)\n",
        "\n",
        "  model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy']) # clasificacion\n",
        "\n",
        "  history = model.fit([X_train[c] for c in categoricas] + [X_train[continuas]], y_train_emb_nn, \n",
        "                      verbose=False,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  loss, accuracy  = model.evaluate([X_test[c] for c in categoricas] + [X_test[continuas]], y_test_emb_nn, verbose=False)\n",
        "  return loss, accuracy \n",
        "\n",
        "mixed_nn_model_eval(cromosoma)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.26803070306777954, 0.8950892686843872)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoHYmoxNPhxG",
        "outputId": "3c433a6b-8bcc-484b-cb31-814e1ee65ce5"
      },
      "source": [
        "cromosomas = cromosomas_al_azar(5)\n",
        "\n",
        "aptitudes = [mixed_nn_model_eval(i) for i in cromosomas]"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.2717418968677521, 0.8727678656578064),\n",
              " (0.25574061274528503, 0.8883928656578064),\n",
              " (0.27253487706184387, 0.8683035969734192),\n",
              " (0.268725723028183, 0.8950892686843872),\n",
              " (0.2581373155117035, 0.8839285969734192)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuYzOhjDqtID"
      },
      "source": [
        "# Todo junto\n",
        "# con 10 cromosomas de poblacion inicial y 5 generaciones\n",
        "GENERACIONES = 5\n",
        "TAM_POBLACION = 10\n",
        "Q_EPOCHS = [100,300,500]\n",
        "BATCH_SIZES = [64,128,256]\n",
        "\n",
        "poblacion = cromosomas_al_azar(TAM_POBLACION)\n",
        "mejores = []\n",
        "for generacion in range(GENERACIONES):\n",
        "\n",
        "  for epochs in Q_EPOCHS:\n",
        "\n",
        "    for batch_sizes in BATCH_SIZES:\n",
        "          \n",
        "        aptitudes = [mixed_nn_model_eval(i, batch_size=batch_sizes, epochs=epochs) for i in poblacion]\n",
        "        mejores.append(seleccionar(poblacion, aptitudes, 2))\n",
        "        mejores = sorted(mejores, key=lambda x:x[0][1], reverse=True)\n",
        "\n",
        "        nuevo_individuo_1, nuevo_individuo_2 = cruzar(mejores[0][0][1], mejores[0][1][1])\n",
        "        nuevo_individuo_3, nuevo_individuo_4 = cruzar(mejores[0][1][1], mejores[0][0][1])\n",
        "\n",
        "        mutacion_1,mutacion_2 = mutar(mejores[0][0][1]), mutar(mejores[0][1][1])\n",
        "\n",
        "        poblacion = list(list(zip(*mejores[0]))[1]) + \\\n",
        "            [nuevo_individuo_1, nuevo_individuo_2, nuevo_individuo_3, nuevo_individuo_4] + \\\n",
        "            [mutacion_1, mutacion_2]\n",
        "\n",
        "  print(f'Generacion:{generacion}. El mejor hasta ahora es:', mejores[0][0],', epochs:', epochs, ', batch_size:', batch_sizes)\n",
        "\n",
        "  #  ((0.2693330645561218, 0.9040178656578064), [125, 10, 85])],\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}